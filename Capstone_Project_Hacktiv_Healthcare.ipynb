{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZ5GIVZgea3TVfEcbgpZ1x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fausta-Tata/healthcare-ai-classification-summarization/blob/main/Capstone_Project_Hacktiv_Healthcare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VC9DgUa_9P2C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3f32cd7-d402-4785-c96a-13d55c1fa91e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.75)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.43)\n",
            "Collecting requests<3,>=2.32.5 (from langchain_community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.23)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.6.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.6.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (0.24.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain_community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain_community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain_community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain_community-0.3.29 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n",
            "Collecting replicate\n",
            "  Downloading replicate-1.0.7-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from replicate) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from replicate) (25.0)\n",
            "Requirement already satisfied: pydantic>1.10.7 in /usr/local/lib/python3.12/dist-packages (from replicate) (2.11.7)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from replicate) (4.15.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.21.0->replicate) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.21.0->replicate) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.21.0->replicate) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.21.0->replicate) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.21.0->replicate) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>1.10.7->replicate) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>1.10.7->replicate) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>1.10.7->replicate) (0.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.3.1)\n",
            "Downloading replicate-1.0.7-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.6/48.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: replicate\n",
            "Successfully installed replicate-1.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_community\n",
        "!pip install replicate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup Library\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "from langchain_community.llms import Replicate\n",
        "from google.colab import userdata\n",
        "import textwrap"
      ],
      "metadata": {
        "id": "KBJjGZl3iq_t"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the API token\n",
        "api_token = userdata.get('api_token')\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = api_token"
      ],
      "metadata": {
        "id": "XtiD7rJ9XMkh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# URL Github Healthcare Dataset\n",
        "\n",
        "url = 'https://github.com/Fausta-Tata/healthcare-ai-classification-summarization/raw/refs/heads/main/data/HealthcareDocumentationDatabase.csv'\n"
      ],
      "metadata": {
        "id": "QzcrhzUTJsCs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set model and model parameters\n",
        "model = \"ibm-granite/granite-3.3-8b-instruct\"\n",
        "\n",
        "parameters = {\n",
        "  \"temperature\": 0.1,\n",
        "  \"top_p\": 0.75,\n",
        "  \"max_tokens\": 70,\n",
        "  \"repetition_penalty\": 1.5,\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "F_W3NXxQTlRJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = Replicate(\n",
        "    model = model,\n",
        "    replicate_api_token=api_token,\n",
        "    model_kwargs = parameters\n",
        ")"
      ],
      "metadata": {
        "id": "iKkWfvc4iRSx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_transcription(transcription: str, specialty_list: str):\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert medical assistant. Analyze the following medical transcription.\n",
        "\n",
        "    Transcription:\n",
        "    ---\n",
        "    {transcription}\n",
        "    ---\n",
        "\n",
        "    Tasks:\n",
        "    1. Generate a very concise \"description\" (maximum 20 word in clinical note style) summarizing the patient's condition.\n",
        "    2. Identify the most relevant \"medical_specialty\". You MUST select exactly ONE specialty from this list: {specialty_list}\n",
        "\n",
        "    Output:\n",
        "    Return the result strictly in valid JSON format, like:\n",
        "\n",
        "    {{\n",
        "      \"description\": \"...\",\n",
        "      \"medical_specialty\": \"...\"\n",
        "    }}\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Invoke the model\n",
        "        response = llm.invoke(prompt, parameters=parameters)\n",
        "\n",
        "        # Cleaner and more robust JSON parsing\n",
        "        start_index = response.find('{')\n",
        "        end_index = response.rfind('}') + 1\n",
        "        if start_index == -1 or end_index == 0:\n",
        "            raise json.JSONDecodeError(\"No JSON object found in the response.\", response, 0)\n",
        "\n",
        "        json_str = response[start_index:end_index]\n",
        "        json_response = json.loads(json_str)\n",
        "\n",
        "        return {\n",
        "            \"description\": json_response.get(\"description\", \"N/A\"),\n",
        "            \"medical_specialty\": json_response.get(\"medical_specialty\", \"N/A\")\n",
        "        }\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"\\nFailed to parse JSON. Error: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "ErKAtRklh9-i"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    try:\n",
        "        # Import Healthcare Dataset\n",
        "        df = pd.read_csv(url)\n",
        "        # Drop Null Values\n",
        "        df.dropna(subset=['transcription', 'medical_specialty', 'description'], inplace=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return\n",
        "\n",
        "    # Create a Unique List of Medical Specialties for The Models to Choose From.\n",
        "    unique_specialties = df['medical_specialty'].unique().tolist()\n",
        "    specialty_list_str = \", \".join(f\"'{s.strip()}'\" for s in unique_specialties)\n",
        "\n",
        "    # Taking Random Data Samples\n",
        "    sample_size = 5\n",
        "    sample_df = df.sample(n=sample_size, random_state=27)\n",
        "\n",
        "\n",
        "    # Create Variable for Accuration Process\n",
        "    total_sampel = 0\n",
        "    prediksi_benar = 0\n",
        "\n",
        "    # Analysis Process\n",
        "    for index, row in sample_df.iterrows():\n",
        "        print(f\"\\n---------------- Analisis Data #{index + 1} ----------------\")\n",
        "        original_transcription = row['transcription']\n",
        "        original_specialty = row['medical_specialty'].strip()\n",
        "        original_description = row['description'].strip()\n",
        "\n",
        "        # Call Function AI\n",
        "        ai_result = analyze_transcription(original_transcription, specialty_list_str)\n",
        "\n",
        "        if ai_result:\n",
        "            total_sampel += 1\n",
        "            ai_specialty = ai_result['medical_specialty'].strip()\n",
        "            ai_description = ai_result['description'].strip()\n",
        "\n",
        "            print(\"\\n--- Perbandingan Deskripsi ---\")\n",
        "            print(f\"Deskripsi Asli: {textwrap.fill(original_description, width=100)}\")\n",
        "            print(f\"\\nDeskripsi AI  : {textwrap.fill(ai_description, width=100)}\")\n",
        "\n",
        "            print(\"\\n\\n--- Perbandingan Spesialisasi Medis ---\")\n",
        "            print(f\"Spesialisasi Asli: {original_specialty}\")\n",
        "            print(f\"Spesialisasi AI  : {ai_specialty}\")\n",
        "\n",
        "            # Logic of comparison of AI Results and Original Data\n",
        "            if original_specialty.lower() in ai_specialty.lower():\n",
        "                prediksi_benar += 1\n",
        "                print(\"Status           : Akurat\")\n",
        "            else:\n",
        "                print(\"Status           : Tidak Akurat\")\n",
        "\n",
        "\n",
        "    # Final Accuracy Result\n",
        "    if total_sampel > 0:\n",
        "        akurasi = (prediksi_benar / total_sampel) * 100\n",
        "        print(f\"\\n\\n------ HASIL ANALISIS KESELURUHAN ------\")\n",
        "        print(f\"Total Sampel Dianalisis: {total_sampel}\")\n",
        "        print(f\"Jumlah Prediksi Benar  : {prediksi_benar}\")\n",
        "        print(f\"Tingkat Akurasi Model  : {akurasi:.2f}%\")\n",
        "    else:\n",
        "        print(\"\\nTidak ada sampel yang berhasil dianalisis.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "YQTHIr4ZX2sl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run The Program\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ew6u5jQJexCw",
        "outputId": "8ef9c76c-6783-436d-a417-e17deaef769f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------- Analisis Data #1824 ----------------\n",
            "\n",
            "--- Perbandingan Deskripsi ---\n",
            "Deskripsi Asli: A 19-year-old right-handed male injured in a motor vehicle accident.\n",
            "\n",
            "Deskripsi AI  : 19-year-old with post-traumatic cervical & lumbar radiculopathy, disc herniations, myofascitis,\n",
            "scheduled for EMG study.\n",
            "\n",
            "\n",
            "--- Perbandingan Spesialisasi Medis ---\n",
            "Spesialisasi Asli: Orthopedic\n",
            "Spesialisasi AI  : Neurosurgery\n",
            "Status           : Tidak Akurat\n",
            "\n",
            "---------------- Analisis Data #501 ----------------\n",
            "\n",
            "--- Perbandingan Deskripsi ---\n",
            "Deskripsi Asli: Right middle ear exploration with a Goldenberg TORP reconstruction.\n",
            "\n",
            "Deskripsi AI  : Profound mixed sensorineural conductive hearing loss, otosclerosis, stapes fixation, no round window\n",
            "niche, revision surgery with Goldenberg torp reconstruction.\n",
            "\n",
            "\n",
            "--- Perbandingan Spesialisasi Medis ---\n",
            "Spesialisasi Asli: Surgery\n",
            "Spesialisasi AI  : Otolaryngology\n",
            "Status           : Tidak Akurat\n",
            "\n",
            "---------------- Analisis Data #177 ----------------\n",
            "\n",
            "--- Perbandingan Deskripsi ---\n",
            "Deskripsi Asli: Fertile male with completed family.  Elective male sterilization via bilateral vasectomy.\n",
            "\n",
            "Deskripsi AI  : 34-year-old male underwent elective bilateral vasectomy for sterilization with minimal blood loss.\n",
            "\n",
            "\n",
            "--- Perbandingan Spesialisasi Medis ---\n",
            "Spesialisasi Asli: Surgery\n",
            "Spesialisasi AI  : Urology\n",
            "Status           : Tidak Akurat\n",
            "\n",
            "---------------- Analisis Data #2419 ----------------\n",
            "\n",
            "--- Perbandingan Deskripsi ---\n",
            "Deskripsi Asli: MRI of the brain without contrast to evaluate daily headaches for 6 months in a 57-year-old.\n",
            "\n",
            "Deskripsi AI  : 57-year-old with daily headaches for 6 months, MRI brain normal, no acute infarct, no findings to\n",
            "explain headaches.\n",
            "\n",
            "\n",
            "--- Perbandingan Spesialisasi Medis ---\n",
            "Spesialisasi Asli: Neurology\n",
            "Spesialisasi AI  : Neurology\n",
            "Status           : Akurat\n",
            "\n",
            "---------------- Analisis Data #3309 ----------------\n",
            "\n",
            "--- Perbandingan Deskripsi ---\n",
            "Deskripsi Asli: Left upper extremity amputation.  This 3-year-old male suffered amputation of his left upper\n",
            "extremity with complications of injury.  He presents at this time for further attempts at closure.\n",
            "Left abdominal flap 5 x 5 cm to left forearm, debridement of skin, subcutaneous tissue, muscle, and\n",
            "bone, closure of wounds, placement of VAC negative pressure wound dressing.\n",
            "\n",
            "Deskripsi AI  : 3-year-old male post-left upper extremity amputation, underwent wound debridement, simple closure,\n",
            "abdominal flap transfer, and NPWT.\n",
            "\n",
            "\n",
            "--- Perbandingan Spesialisasi Medis ---\n",
            "Spesialisasi Asli: Cosmetic / Plastic Surgery\n",
            "Spesialisasi AI  : Cosmetic / Plastic Surgery\n",
            "Status           : Akurat\n",
            "\n",
            "\n",
            "------ HASIL ANALISIS KESELURUHAN ------\n",
            "Total Sampel Dianalisis: 5\n",
            "Jumlah Prediksi Benar  : 2\n",
            "Tingkat Akurasi Model  : 40.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZwMuLzdlt9zB"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}